{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSEbnVm1Q6nJ"
      },
      "source": [
        "## IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:50:17.547881Z",
          "iopub.status.busy": "2021-11-13T20:50:17.547588Z",
          "iopub.status.idle": "2021-11-13T20:50:26.196819Z",
          "shell.execute_reply": "2021-11-13T20:50:26.196012Z",
          "shell.execute_reply.started": "2021-11-13T20:50:17.547847Z"
        },
        "id": "ga5de5DULm2v",
        "outputId": "b18cd467-5ff5-422b-c3b0-14e424a83dbc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import ssl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import nltk\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "# !pip install contractions\n",
        "import contractions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "# !pip install tensorflow_hub\n",
        "# import tensorflow_hub as hub\n",
        "# from scipy import spatial\n",
        "tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:50:26.200871Z",
          "iopub.status.busy": "2021-11-13T20:50:26.200636Z",
          "iopub.status.idle": "2021-11-13T20:50:59.445199Z",
          "shell.execute_reply": "2021-11-13T20:50:59.444386Z",
          "shell.execute_reply.started": "2021-11-13T20:50:26.200840Z"
        },
        "id": "nYgZMSAnLm21",
        "outputId": "beccfdc8-72c5-4c73-9c1a-2f9e4fd2266a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path = \"../data/\"\n",
        "train_data = pd.read_csv(os.path.join(path, 'train.csv'), names = ['Rating','Title','Review'],nrows=10000)\n",
        "test_data = pd.read_csv(os.path.join(path, 'test.csv'), names = ['Rating','Title','Review'], nrows = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:50:59.447070Z",
          "iopub.status.busy": "2021-11-13T20:50:59.446615Z",
          "iopub.status.idle": "2021-11-13T20:51:01.332987Z",
          "shell.execute_reply": "2021-11-13T20:51:01.332208Z",
          "shell.execute_reply.started": "2021-11-13T20:50:59.447031Z"
        },
        "id": "o0CUQVxXLm22",
        "outputId": "529c923c-1a32-4971-d068-e582e4740ced",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Since null values are very low as compared to the whole training dataset - we will drop those\n",
        "train_data = train_data.dropna()\n",
        "train_data.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:51:01.335333Z",
          "iopub.status.busy": "2021-11-13T20:51:01.335066Z",
          "iopub.status.idle": "2021-11-13T20:51:01.728931Z",
          "shell.execute_reply": "2021-11-13T20:51:01.728162Z",
          "shell.execute_reply.started": "2021-11-13T20:51:01.335296Z"
        },
        "id": "AriPxa5CLm26",
        "outputId": "dd48abde-e576-4b99-ded0-37117098feae",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Since null values are very low as compared to the whole training dataset - we will drop those\n",
        "test_data = test_data.dropna()\n",
        "test_data.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:51:01.730491Z",
          "iopub.status.busy": "2021-11-13T20:51:01.730146Z",
          "iopub.status.idle": "2021-11-13T20:51:01.736463Z",
          "shell.execute_reply": "2021-11-13T20:51:01.735681Z",
          "shell.execute_reply.started": "2021-11-13T20:51:01.730454Z"
        },
        "id": "hSTZjccQLm29",
        "outputId": "983c1e9c-f859-4860-86e5-2d6cc2671543",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f\"TRAIN DATA: {train_data.shape}\")\n",
        "print(f\"TEST DATA: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:51:01.738825Z",
          "iopub.status.busy": "2021-11-13T20:51:01.737930Z",
          "iopub.status.idle": "2021-11-13T20:51:01.750286Z",
          "shell.execute_reply": "2021-11-13T20:51:01.749407Z",
          "shell.execute_reply.started": "2021-11-13T20:51:01.738786Z"
        },
        "id": "occ3-BtXLm2-",
        "outputId": "bd7a3d00-968d-445a-ef84-9b3b86e1b499",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#looking at some reviews\n",
        "for i in range(5):\n",
        "    print(\"Review #\",i+1)\n",
        "    print(train_data.Review[i])\n",
        "    print(train_data.Title[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T20:51:01.752089Z",
          "iopub.status.busy": "2021-11-13T20:51:01.751687Z",
          "iopub.status.idle": "2021-11-13T20:51:01.763173Z",
          "shell.execute_reply": "2021-11-13T20:51:01.762446Z",
          "shell.execute_reply.started": "2021-11-13T20:51:01.752054Z"
        },
        "id": "7PVFHtnQLm2-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Remove unwanted characters, stopwords, and format the matter to create fewer nulls word embeddings\n",
        "stops = stopwords.words('english')\n",
        "def clean_matter(matter, remove_stopwords = True, stops = stops):\n",
        "    # Convert words to lower case\n",
        "    matter = str(matter)\n",
        "    matter = matter.lower()\n",
        "    \n",
        "    # Replace contractions with their longer forms \n",
        "    matter = ' '.join([contractions.fix(word) for word in matter.split(\" \")])    \n",
        "    \n",
        "    # Format words and remove unwanted characters\n",
        "    matter = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', matter, flags=re.MULTILINE)\n",
        "    matter = re.sub(r'\\<a href', ' ', matter)\n",
        "    matter = re.sub(r'&amp;', '', matter) \n",
        "    matter = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', matter)\n",
        "    matter = re.sub(r'<br />', ' ', matter)\n",
        "    matter = re.sub(r'\\'', ' ', matter)\n",
        "    \n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        matter = matter.split()\n",
        "        matter = [w for w in matter if not w in stops]\n",
        "        matter = \" \".join(matter)\n",
        "\n",
        "    return matter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ews2DcNrofMw",
        "outputId": "01f36ec6-50fd-4de8-b5ef-733ac3714ef7"
      },
      "outputs": [],
      "source": [
        "print(f\"TRAIN DATA: {train_data.shape}\")\n",
        "print(f\"TEST DATA: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:51:01.764370Z",
          "iopub.status.busy": "2021-11-13T20:51:01.764176Z",
          "iopub.status.idle": "2021-11-13T21:14:00.435283Z",
          "shell.execute_reply": "2021-11-13T21:14:00.433756Z",
          "shell.execute_reply.started": "2021-11-13T20:51:01.764348Z"
        },
        "id": "E_yyVBelLm3D",
        "outputId": "581447b0-3092-446f-8660-b2341aab9f71",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_data['Title'] = train_data['Title'].apply(lambda x: clean_matter(x, remove_stopwords = False))\n",
        "train_data['Review'] = train_data['Review'].apply(lambda x: clean_matter(x, remove_stopwords = True))\n",
        "train_data['Title'] = train_data['Title'].apply(lambda x : '_START_ '+ x + ' _END_')\n",
        "\n",
        "for i in range(2):\n",
        "    print('Title:', train_data['Title'][i],'Review:', train_data['Review'][i], sep='\\n')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T21:14:00.436892Z",
          "iopub.status.busy": "2021-11-13T21:14:00.436624Z",
          "iopub.status.idle": "2021-11-13T21:14:09.773095Z",
          "shell.execute_reply": "2021-11-13T21:14:09.772224Z",
          "shell.execute_reply.started": "2021-11-13T21:14:00.436856Z"
        },
        "id": "CiFS7ZzmLm3D",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Title_length = [len(x.split()) for x in train_data.Title]\n",
        "Review_length = [len(x.split()) for x in train_data.Review]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T21:14:09.777025Z",
          "iopub.status.busy": "2021-11-13T21:14:09.776606Z",
          "iopub.status.idle": "2021-11-13T21:14:40.613277Z",
          "shell.execute_reply": "2021-11-13T21:14:40.612587Z",
          "shell.execute_reply.started": "2021-11-13T21:14:09.776990Z"
        },
        "id": "OLzqfvsbLm3F",
        "outputId": "ebea1c07-df50-4c5f-a842-e8b18cf9b857",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
        "ax1.hist(Title_length, bins = 20)\n",
        "ax2.hist(Review_length, bins = 20)\n",
        "\n",
        "ax1.title.set_text(\"Words in Titles\")\n",
        "ax2.title.set_text(\"Words in Reviews\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO6Qaq7BLm3G"
      },
      "source": [
        "## Cleaning Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T21:14:40.615160Z",
          "iopub.status.busy": "2021-11-13T21:14:40.614678Z",
          "iopub.status.idle": "2021-11-13T21:19:40.478015Z",
          "shell.execute_reply": "2021-11-13T21:19:40.477201Z",
          "shell.execute_reply.started": "2021-11-13T21:14:40.615113Z"
        },
        "id": "5hLtuRn1Lm3I",
        "outputId": "d31378f2-fb12-4730-d956-104919082f97",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_data['Title'] = test_data['Title'].apply(lambda x: clean_matter(x, remove_stopwords = False))\n",
        "test_data['Review'] = test_data['Review'].apply(lambda x: clean_matter(x, remove_stopwords = True))\n",
        "test_data['Title'] = test_data['Title'].apply(lambda x : '_START_ '+ x + ' _END_')\n",
        "\n",
        "for i in range(2):\n",
        "    print('Title:', test_data['Title'][i],'Review:', test_data['Review'][i], sep='\\n')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T21:19:40.479827Z",
          "iopub.status.busy": "2021-11-13T21:19:40.479272Z",
          "iopub.status.idle": "2021-11-13T21:19:42.577331Z",
          "shell.execute_reply": "2021-11-13T21:19:42.576509Z",
          "shell.execute_reply.started": "2021-11-13T21:19:40.479787Z"
        },
        "id": "y6jU8023Lm3J",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Title_length_test = [len(x.split()) for x in test_data.Title]\n",
        "Review_length_test = [len(x.split()) for x in test_data.Review]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T21:19:42.578835Z",
          "iopub.status.busy": "2021-11-13T21:19:42.578533Z",
          "iopub.status.idle": "2021-11-13T21:19:49.240249Z",
          "shell.execute_reply": "2021-11-13T21:19:49.239586Z",
          "shell.execute_reply.started": "2021-11-13T21:19:42.578798Z"
        },
        "id": "DbpfL2FOLm3J",
        "outputId": "fbf07b63-991f-419c-a058-eb1c0b5355bf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
        "ax1.hist(Title_length_test, bins = 20)\n",
        "ax2.hist(Review_length_test, bins = 20)\n",
        "\n",
        "ax1.title.set_text(\"Words in Title\")\n",
        "ax2.title.set_text(\"Words in Review\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHd33DSRomAy",
        "outputId": "bceb1956-be69-4770-a494-26c975dea317"
      },
      "outputs": [],
      "source": [
        "print(f\"TRAIN DATA: {train_data.shape}\")\n",
        "print(f\"TEST DATA: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmqsSh1NLm3K"
      },
      "source": [
        "## GLOVE EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T21:19:49.242155Z",
          "iopub.status.busy": "2021-11-13T21:19:49.241484Z",
          "iopub.status.idle": "2021-11-13T21:20:17.478646Z",
          "shell.execute_reply": "2021-11-13T21:20:17.477811Z",
          "shell.execute_reply.started": "2021-11-13T21:19:49.242113Z"
        },
        "id": "JG4XcjEdLm3L",
        "outputId": "98c4f65f-1453-4fd5-915e-4851ff465221",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "glove_size = 300\n",
        "# with open('../data/glove.840B.300d.pkl', 'rb') as fp:\n",
        "#     glove = pickle.load(fp)\n",
        "\n",
        "f = open(os.path.join(path, 'glove.840B.300d.txt'), encoding='utf-8')\n",
        "glove = dict()\n",
        "i = 1\n",
        "for line in f:\n",
        "    values = line.split(\" \")\n",
        "    if i < 5:\n",
        "        print(values)\n",
        "        i = i + 1\n",
        "    glove[values[0]] = np.asarray(values[1:], dtype='float32')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T21:20:17.512237Z",
          "iopub.status.busy": "2021-11-13T21:20:17.512004Z"
        },
        "id": "zFGHmXjNLm3N",
        "outputId": "ce937f58-4585-45cb-d231-35caf697bdeb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "words_source_ALL = []\n",
        "for i in train_data['Review'] :\n",
        "  words_source_ALL.extend(i.split(' '))\n",
        "for i in test_data['Review'] :\n",
        "  words_source_ALL.extend(i.split(' '))\n",
        "\n",
        "print(\"TOTAL WORDS: \", len(words_source_ALL))\n",
        "\n",
        "words_source_ALL = set(words_source_ALL)\n",
        "print(\"UNIQUE WORDS: \", len(words_source_ALL))\n",
        "\n",
        "inter_words = set(glove.keys()).intersection(words_source_ALL)\n",
        "print(\"WORDS COMMON IN GLOVE AND CORPUS: {} = {}% \".format(len(inter_words), np.round((float(len(inter_words))/len(words_source_ALL))\n",
        "*100)))\n",
        "\n",
        "words_corpus_source_ALL = {}\n",
        "words_glove = set(glove.keys())\n",
        "for i in words_source_ALL:\n",
        "  if i in words_glove:\n",
        "    words_corpus_source_ALL[i] = glove[i]\n",
        "print(\"LENGTH OF WORD2VEC: \", len(words_corpus_source_ALL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXxP_9jVLm3O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def num(text):\n",
        "  words = [w for w in text.split() if not w in inter_words]\n",
        "  return len(words)\n",
        "\n",
        "train_data['unique'] = train_data['Review'].apply(num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pei3Q1XLm3P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_data = train_data[train_data['unique'] < 4]\n",
        "train_data.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SQ7MgvfLm3U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max_length_x = max(Review_length + Review_length_test)\n",
        "max_length_y = max(Title_length + Title_length_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nY5tR-JLm3V",
        "outputId": "6c8b5346-a640-4133-f89e-455f0c6cb47b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_data.Review =  pd.Series(test_data.Review, dtype=\"string\")\n",
        "test_data.Title =  pd.Series(test_data.Title, dtype=\"string\")\n",
        "\n",
        "train_data.Review =  pd.Series(train_data.Review, dtype=\"string\")\n",
        "train_data.Title =  pd.Series(train_data.Title, dtype=\"string\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqccUDMPLm3W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "all_sentences = train_data.Review.tolist() + train_data.Title.tolist() + test_data.Review.tolist() + test_data.Title.tolist()\n",
        "\n",
        "x_t = Tokenizer()\n",
        "x_t.fit_on_texts(all_sentences)\n",
        "x_vocab_size = len(x_t.word_index) + 1\n",
        "\n",
        "\n",
        "encoded_xtrain = x_t.texts_to_sequences(train_data['Review'])\n",
        "encoded_xtest = x_t.texts_to_sequences(test_data['Review'])\n",
        "\n",
        "padded_xtrain = pad_sequences(encoded_xtrain, maxlen=max_length_x, padding='post')\n",
        "padded_xtest = pad_sequences(encoded_xtest, maxlen=max_length_x, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndd6CQeQLm3W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "all_y_sentences = train_data.Title.tolist() + test_data.Title.tolist()\n",
        "\n",
        "y_t = Tokenizer()\n",
        "y_t.fit_on_texts(all_y_sentences)\n",
        "y_vocab_size = len(y_t.word_index) + 1\n",
        "\n",
        "encoded_ytrain = y_t.texts_to_sequences(train_data['Title'])\n",
        "encoded_ytest = y_t.texts_to_sequences(test_data['Title'])\n",
        "\n",
        "padded_ytrain = pad_sequences(encoded_ytrain, maxlen=max_length_y, padding='post')\n",
        "padded_ytest = pad_sequences(encoded_ytest, maxlen=max_length_y, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czU5dGcYLm3X",
        "outputId": "e5462fda-3e31-4f23-a786-9aa64f9e1778",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f'LOADED {len(glove)} WORD VECTORS.')\n",
        "\n",
        "embedding_matrix = np.zeros((x_vocab_size, glove_size))\n",
        "for word, i in x_t.word_index.items():\n",
        "    embedding_vector = glove.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYsZEUYSbjYr"
      },
      "source": [
        "# LSTM Seq2Seq Model With ATTENTION Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkzlLdlQLm3Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class AttentionLayer(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "          \n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  \n",
        "            \n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            \n",
        "            fake_state = K.zeros_like(inputs)  \n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  \n",
        "            fake_state = K.expand_dims(fake_state)  \n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  \n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  \n",
        "\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n",
        "\n",
        "\n",
        "latent_dim = 64\n",
        "\n",
        "K.clear_session() \n",
        "\n",
        "encoder_inputs = Input(shape=(max_length_x,)) \n",
        "enc_emb = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False)(encoder_inputs) \n",
        "\n",
        "#LSTM \n",
        "encoder_lstm = LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm(enc_emb) \n",
        "\n",
        "# Decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFKwb5KtLm3a",
        "outputId": "247c8f10-2958-46ec-c887-5a8d717e87d6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', experimental_run_tf_function=False)\n",
        "\n",
        "checkpoint_filepath = '../model/model.{epoch:02d}-{val_loss:.2f}.h5'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath = checkpoint_filepath,\n",
        "                                save_weights_only = True,\n",
        "                                monitor = 'val_loss', \n",
        "                                mode = 'min',\n",
        "                                save_best_only = True, \n",
        "                                save_freq = \"epoch\")\n",
        "\n",
        "es = EarlyStopping( monitor = 'val_loss', \n",
        "                    mode = 'min', \n",
        "                    verbose = 1, \n",
        "                    patience = 1)\n",
        "history=model.fit(\n",
        "                    [padded_xtrain, padded_ytrain[:,:-1]], \n",
        "                    padded_ytrain.reshape(padded_ytrain.shape[0], padded_ytrain.shape[1], 1)[:, 1:],\n",
        "                    epochs = 10,\n",
        "                    batch_size = 128, \n",
        "                    validation_split = 0.1, \n",
        "                    callbacks = [es, model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmLPUOajWyYL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T20:43:23.164329Z",
          "iopub.status.busy": "2021-11-13T20:43:23.163946Z",
          "iopub.status.idle": "2021-11-13T20:43:24.379478Z",
          "shell.execute_reply": "2021-11-13T20:43:24.378728Z",
          "shell.execute_reply.started": "2021-11-13T20:43:23.164288Z"
        },
        "id": "BluEGolFLm3b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# change path to new model if any issue\n",
        "model.load_weights(\"../model/summ_model.h5\")\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T20:43:30.412432Z",
          "iopub.status.busy": "2021-11-13T20:43:30.411885Z",
          "iopub.status.idle": "2021-11-13T20:43:30.416720Z",
          "shell.execute_reply": "2021-11-13T20:43:30.416047Z",
          "shell.execute_reply.started": "2021-11-13T20:43:30.412393Z"
        },
        "id": "1uMrImP2Lm3d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "reverse_target_word_index = y_t.index_word \n",
        "reverse_source_word_index = x_t.index_word \n",
        "target_word_index = y_t.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T20:43:36.307271Z",
          "iopub.status.busy": "2021-11-13T20:43:36.307025Z",
          "iopub.status.idle": "2021-11-13T20:43:36.651475Z",
          "shell.execute_reply": "2021-11-13T20:43:36.650818Z",
          "shell.execute_reply.started": "2021-11-13T20:43:36.307244Z"
        },
        "id": "ZB9Gu3HHLm3f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_length_x,latent_dim))\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T20:43:37.922743Z",
          "iopub.status.busy": "2021-11-13T20:43:37.922203Z",
          "iopub.status.idle": "2021-11-13T20:43:37.930079Z",
          "shell.execute_reply": "2021-11-13T20:43:37.929281Z",
          "shell.execute_reply.started": "2021-11-13T20:43:37.922705Z"
        },
        "id": "c4iul--mLm3f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    input_seq= input_seq.reshape(1,max_length_x)\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        " \n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_length_y-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-13T20:43:38.692929Z",
          "iopub.status.busy": "2021-11-13T20:43:38.691885Z",
          "iopub.status.idle": "2021-11-13T20:43:38.699188Z",
          "shell.execute_reply": "2021-11-13T20:43:38.698297Z",
          "shell.execute_reply.started": "2021-11-13T20:43:38.692883Z"
        },
        "id": "35tnx0nhLm3g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-11-13T20:43:39.648050Z",
          "iopub.status.busy": "2021-11-13T20:43:39.647460Z",
          "iopub.status.idle": "2021-11-13T20:43:43.651476Z",
          "shell.execute_reply": "2021-11-13T20:43:43.650795Z",
          "shell.execute_reply.started": "2021-11-13T20:43:39.648018Z"
        },
        "id": "7Q53Xi03Lm3g",
        "outputId": "d40b5c5f-88bb-4af0-be7b-39e3e73ce14e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(path + 'test.csv', names = ['Rating','Title','Review'], nrows = 100)\n",
        "for i in range(10):\n",
        "    print('Original Review:', test_data.iloc[i, 2])\n",
        "    print(\"Review:\",seq2text(padded_xtest[i]))\n",
        "    print(\"Original summary:\",seq2summary(padded_ytest[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(padded_xtest[i]))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Swx9ydRm2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b_beOyPRmq9",
        "outputId": "f4b11ebd-97a7-43fb-a25c-fda10b08f059"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def BLEU_Score(y_test, y_pred):\n",
        "    references = [[seq2summary(y_test).split(\" \")]]\n",
        "    candidates = [decode_sequence(y_pred.reshape(1,max_length_x)).split(\" \")]\n",
        "    return corpus_bleu(references, candidates)\n",
        "\n",
        "scores=[]\n",
        "\n",
        "for i in range(0,500):\n",
        "    scores.append(BLEU_Score(padded_ytest[i],padded_xtest[i]))\n",
        "    \n",
        "print(np.mean(scores))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "boZJiVbPRWvD"
      ],
      "machine_shape": "hm",
      "name": "summarization-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
